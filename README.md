# Fuzzy-Clustering-Using-C-Means-Clustering-Technique
In this repository, experimental dataset of vibration-based energy harvester is clustered using fuzzy logic and the C-means technique. 
Fuzzy c-means (FCM) is a data clustering technique wherein each data point belongs to a cluster to some degree which is determined by grade of a membership. This technique provides a method showing how to group data points that populate some multidimensional space into a specific number of different clusters. The command line function ‘fcm’ (fuzzy c means clustering) initiates with an initial guess for the cluster centers, which are intended to highlight and coincide with  the mean location of each cluster.  However, the nominated initial guess for these cluster centers is most likely incorrect. ‘fcm’ assigns every single data point a membership grade for each cluster. By iteratively updating the cluster centers and the membership grades for each data point, ‘fcm’ iteratively moves the cluster centers to the right location within a dataset. This iteration is based on minimizing an objective (cost) function representing the distance from any given data point to a cluster center weighted by that data point's membership grade. In Matlab, the command line function ‘fcm’ outputs a list of cluster centers along with several membership grades for each data point. Fuzzy qualities of each cluster disclosed by ‘fcm’, can be taken to build the fuzzy membership functions and the fuzzy inference system (FIS). 
Subtractive clustering 
As for the cases in which, there is no clear idea of  how many clusters there should be for a given set of data, subtractive clustering is a fast, one-pass algorithm for estimating the number of clusters and the cluster centers for the dataset. In Matlab, the cluster estimates obtained from the ’subclust’ function, can be used to initialize iterative optimization-based clustering methods (fcm) and model identification methods (like anfis). The ‘subclust’ function finds the clusters using the subtractive clustering method.     
First the voltage dataset is clustered using the C-Means method. The pertinent code is written in MATLAB at the command line. Using the mentioned method, one needs to first clarify the number of clusters. Assuming 3 clusters for the experimental dataset, options should be determined as well. Options in ‘fcm’ (fuzzy C-means clustering) is a row vector including 4 elements. The first element (options(1)) is the exponent of the fuzzy partition matrix shown by ‘U’. before proceeding further, the fuzzy partition matrix is a N_c by N_d matrix. N_c representing the number of rows is identical to the number of clusters. U(i,j) indicates the degree of membership of the jth data point in the ith cluster. For a given datapoint, sum of the membership values of all clusters in equal to 1. In other words, sum of the entities of each column of the fuzzy partition matrix is equal to 1 (∑_(j=1)^(N_j)▒U_(i,j) =1). First element on the options matrix controls the amount of fuzzy overlap between different clusters. In MATLAB the default value for such an exponent is 2. Greater values of this exponent indicate greater overlaps. It means with big exponent values, cluster boundaries are less crips and have more overlaps. In such a case which happens with big (wide) datasets, the calculated cluster centers are probably very close to each other. In such a case, each datapoint has approximately the same amount of membership in all clusters. In most of the clustering cases, it is recommended to adopt small values of option(1) (fuzzy partition matrix exponent) which leads to less overlap between fuzzy clusters. However, this number should be bigger than 1 to cover all of the datapoints in a dataset. Second entity of the option matrix is options(2) pertains to the maximum number of iterations. This value is considered by 100 as default. Obviously increasing the option(s) leads to more computations but more accuracy. Third entity is the minimum improvement value of objective function between two successive (consecutive) iterations. Default value is 10^(-5). Optimization in clustering will stop if the objective function improvement between the last two final iterations is less than this third entity. This entity determines the accuracy of clustering. The last entity of the option matrix is a verbose function of ‘true’ or ‘false’. This option enables the MATLAB to either display or hide the objective function values per each iteration and loop. With all this explanation, classifying the dataset into the specific cluster with largest membership value is done. 

![image](https://user-images.githubusercontent.com/61955953/156657702-b5cce1ed-8dbb-4bec-b1cd-f39e5e4f1850.png)

The above figure shows the objective function values versus iteration counts with 0.0005 as the minimum function improvement. Obviously, throughout the initial iterations (<5) the objective function decreases sharply and steeply. After about 5 iterations the slope of decrement is reduced and the optimization algorithm stops around 70 iterations where the improvement between the last two functions is less than 0.0005. 

![image](https://user-images.githubusercontent.com/61955953/156657734-99e5cdda-0c46-478f-b02b-19c360d8c550.png)

The above figure shows the clustering of the voltage dataset into three various clusters. Certainly number of elements in each cluster does not necessarily equate with the other cluster. In this clustering effort, 47 elements exist in the third cluster, 42 in the second and 11elements appear in the first cluster. Center of each cluster is depicted in cross marks. Fuzzy partition matrix is considered as 2, maximum number of iterations is set to 500, and minimum objective function improvement is considered as 0.0005.  
Using the ‘genfis’ function, it is viable to train the corresponding fuzzy inference system (FIS) for the accomplished clustering algorithm. To customize the fuzzy inference system according to the clustering options, one can specify the system using ‘genfisOptions’ function using the ‘option’ matrix which is already used in clustering the dataset. 

![image](https://user-images.githubusercontent.com/61955953/156657785-4e1d265c-ba21-4453-bc25-87a66e713fdc.png)

![image](https://user-images.githubusercontent.com/61955953/156657797-68909f8c-b4de-4122-83c9-29711ac59146.png)

Further analysis over C-Means clustering can be accomplished in terms of adjusting the amount of overlap between different fuzzy clusters and to see how this option(1) (fuzzy partition matrix exponent) alters the performance of the clustering algorithm.    

![image](https://user-images.githubusercontent.com/61955953/156657834-1ab4fffd-4d02-48e4-ac81-cd1c210bb3b3.png)


Considering four disparate values of fuzzy partition matrix exponent as M=1.1,2,3,4 and keeping constant values of other option values; clustering figure shows that for smaller numbers of M, crisper boundaries are observed and big values of M result in datapoints which belong to two or even more clusters. A given datapoint is classified into the cluster for which it has the highest membership value. A maximum membership value of 0.5 indicates that the point belongs to both clusters equally. The datapoints with marked yellow cross signs have maximum membership values below 0.6. these points have a greater degree of uncertainty in their corresponding membership. More datapoints with low maximum membership values indicate a greater degree of fuzzy overlap in the clustering result. The average maximum membership value shown by Ave. Max. provides quantitative description of the overlap. In short, bigger average maximum values occurs with smaller fuzzy partition matrix exponent which shows crisp clusters with small or no overlaps. Conversely, increasing the M leads to smaller average maximum values and more overlapped clusters which decreases the efficacy of the clustering algorithm. 
